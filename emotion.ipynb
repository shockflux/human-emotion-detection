{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k4M58XVB-EV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "dataset_path = '/content/drive/My Drive/face/challenges-in-representation-learning-facial-expression-recognition-challenge/fer2013/fer2013/fer2013.csv'\n",
        "image_size=(48,48)\n",
        " \n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = pd.get_dummies(data['emotion']).values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrhvXD2uHVln",
        "colab_type": "code",
        "outputId": "0171e054-54fb-4bb2-c3e8-8350623e6bc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Activation, Convolution2D, Dropout, Conv2D\n",
        "from keras.layers import AveragePooling2D, BatchNormalization\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import SeparableConv2D\n",
        "from keras import layers\n",
        "from keras.regularizers import l2\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        " \n",
        "# parameters\n",
        "batch_size = 32\n",
        "num_epochs = 50\n",
        "input_shape = (48, 48, 1)\n",
        "verbose = 1\n",
        "num_classes = 7\n",
        "patience = 50\n",
        "base_path = '/content/drive/My Drive/models/'\n",
        "l2_regularization=0.01\n",
        " \n",
        "# data generator\n",
        "data_generator = ImageDataGenerator(\n",
        "                        featurewise_center=False,\n",
        "                        featurewise_std_normalization=False,\n",
        "                        rotation_range=10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True)\n",
        " \n",
        "# model parameters\n",
        "regularization = l2(l2_regularization)\n",
        " \n",
        "# base\n",
        "img_input = Input(input_shape)\n",
        "x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(img_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        " \n",
        "# module 1\n",
        "residual = Conv2D(16, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "residual = BatchNormalization()(residual)\n",
        "x = SeparableConv2D(16, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = SeparableConv2D(16, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "x = layers.add([x, residual])\n",
        " \n",
        "# module 2\n",
        "residual = Conv2D(32, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "residual = BatchNormalization()(residual)\n",
        "x = SeparableConv2D(32, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = SeparableConv2D(32, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "x = layers.add([x, residual])\n",
        " \n",
        "# module 3\n",
        "residual = Conv2D(64, (1, 1), strides=(2, 2),padding='same', use_bias=False)(x)\n",
        "residual = BatchNormalization()(residual)\n",
        "x = SeparableConv2D(64, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = SeparableConv2D(64, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "x = layers.add([x, residual])\n",
        " \n",
        "# module 4\n",
        "residual = Conv2D(128, (1, 1), strides=(2, 2),padding='same', use_bias=False)(x)\n",
        "residual = BatchNormalization()(residual)\n",
        "x = SeparableConv2D(128, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = SeparableConv2D(128, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "x = layers.add([x, residual])\n",
        "x = Conv2D(num_classes, (3, 3), padding='same')(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "output = Activation('softmax',name='predictions')(x)\n",
        " \n",
        "model = Model(img_input, output)\n",
        "model.compile(optimizer='adam', loss='mse',metrics=['accuracy'])\n",
        "model.summary()\n",
        " \n",
        "# callbacks\n",
        "log_file_path = base_path + '_emotion_training.log'\n",
        "csv_logger = CSVLogger(log_file_path, append=False)\n",
        "early_stop = EarlyStopping('val_loss', patience=patience)\n",
        "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=int(patience/4), verbose=1)\n",
        "trained_models_path = base_path + '_mini_XCEPTION'\n",
        "model_names = trained_models_path + '.{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
        "model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,save_best_only=True)\n",
        "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
        " \n",
        "model.fit_generator(data_generator.flow(xtrain, ytrain,batch_size),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1, callbacks=callbacks,\n",
        "                        validation_data=(xtest,ytest))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 48, 48, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 46, 46, 8)    72          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 46, 46, 8)    32          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 46, 46, 8)    0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 44, 44, 8)    576         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 44, 44, 8)    32          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 44, 44, 8)    0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 44, 44, 16)   200         activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 44, 44, 16)   64          separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 44, 44, 16)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 44, 44, 16)   400         activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 44, 44, 16)   64          separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 22, 22, 16)   128         activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 22, 22, 16)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 22, 22, 16)   64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 22, 22, 16)   0           max_pooling2d_1[0][0]            \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 22, 22, 32)   656         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 22, 22, 32)   128         separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 22, 22, 32)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 22, 22, 32)   1312        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 22, 22, 32)   128         separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 11, 11, 32)   512         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 11, 11, 32)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 11, 11, 32)   128         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 11, 11, 32)   0           max_pooling2d_2[0][0]            \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 11, 11, 64)   2336        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 11, 11, 64)   256         separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 11, 11, 64)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_6 (SeparableCo (None, 11, 11, 64)   4672        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 11, 11, 64)   256         separable_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 6, 6, 64)     2048        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 6, 6, 64)     0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 6, 6, 64)     256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 6, 6, 64)     0           max_pooling2d_3[0][0]            \n",
            "                                                                 batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_7 (SeparableCo (None, 6, 6, 128)    8768        add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 6, 6, 128)    512         separable_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 6, 6, 128)    0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_8 (SeparableCo (None, 6, 6, 128)    17536       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 6, 6, 128)    512         separable_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 3, 3, 128)    8192        add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 3, 3, 128)    0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 3, 3, 128)    512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 3, 3, 128)    0           max_pooling2d_4[0][0]            \n",
            "                                                                 batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 3, 3, 7)      8071        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 7)            0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Activation)        (None, 7)            0           global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 58,423\n",
            "Trainable params: 56,951\n",
            "Non-trainable params: 1,472\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "898/897 [==============================] - 254s 283ms/step - loss: 0.1276 - accuracy: 0.3231 - val_loss: 0.1116 - val_accuracy: 0.3757\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.11163, saving model to /content/drive/My Drive/models/_mini_XCEPTION.01-0.38.hdf5\n",
            "Epoch 2/50\n",
            "898/897 [==============================] - 251s 280ms/step - loss: 0.1024 - accuracy: 0.4248 - val_loss: 0.0981 - val_accuracy: 0.4525\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.11163 to 0.09806, saving model to /content/drive/My Drive/models/_mini_XCEPTION.02-0.45.hdf5\n",
            "Epoch 3/50\n",
            "898/897 [==============================] - 251s 279ms/step - loss: 0.0967 - accuracy: 0.4616 - val_loss: 0.1049 - val_accuracy: 0.4028\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.09806\n",
            "Epoch 4/50\n",
            "898/897 [==============================] - 250s 279ms/step - loss: 0.0929 - accuracy: 0.4874 - val_loss: 0.0952 - val_accuracy: 0.4816\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.09806 to 0.09516, saving model to /content/drive/My Drive/models/_mini_XCEPTION.04-0.48.hdf5\n",
            "Epoch 5/50\n",
            "898/897 [==============================] - 250s 279ms/step - loss: 0.0901 - accuracy: 0.5081 - val_loss: 0.0895 - val_accuracy: 0.5111\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.09516 to 0.08947, saving model to /content/drive/My Drive/models/_mini_XCEPTION.05-0.51.hdf5\n",
            "Epoch 6/50\n",
            "898/897 [==============================] - 251s 279ms/step - loss: 0.0885 - accuracy: 0.5169 - val_loss: 0.1025 - val_accuracy: 0.4246\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.08947\n",
            "Epoch 7/50\n",
            "898/897 [==============================] - 251s 279ms/step - loss: 0.0862 - accuracy: 0.5312 - val_loss: 0.0887 - val_accuracy: 0.5079\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.08947 to 0.08869, saving model to /content/drive/My Drive/models/_mini_XCEPTION.07-0.51.hdf5\n",
            "Epoch 8/50\n",
            "898/897 [==============================] - 251s 280ms/step - loss: 0.0850 - accuracy: 0.5396 - val_loss: 0.0888 - val_accuracy: 0.5141\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.08869\n",
            "Epoch 9/50\n",
            "898/897 [==============================] - 250s 279ms/step - loss: 0.0839 - accuracy: 0.5450 - val_loss: 0.0848 - val_accuracy: 0.5300\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.08869 to 0.08484, saving model to /content/drive/My Drive/models/_mini_XCEPTION.09-0.53.hdf5\n",
            "Epoch 10/50\n",
            "898/897 [==============================] - 251s 280ms/step - loss: 0.0827 - accuracy: 0.5553 - val_loss: 0.0916 - val_accuracy: 0.4994\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.08484\n",
            "Epoch 11/50\n",
            "898/897 [==============================] - 251s 280ms/step - loss: 0.0824 - accuracy: 0.5549 - val_loss: 0.0911 - val_accuracy: 0.5064\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.08484\n",
            "Epoch 12/50\n",
            "898/897 [==============================] - 252s 280ms/step - loss: 0.0811 - accuracy: 0.5663 - val_loss: 0.0898 - val_accuracy: 0.5208\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.08484\n",
            "Epoch 13/50\n",
            "898/897 [==============================] - 251s 279ms/step - loss: 0.0807 - accuracy: 0.5681 - val_loss: 0.0827 - val_accuracy: 0.5580\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.08484 to 0.08270, saving model to /content/drive/My Drive/models/_mini_XCEPTION.13-0.56.hdf5\n",
            "Epoch 14/50\n",
            "898/897 [==============================] - 250s 278ms/step - loss: 0.0799 - accuracy: 0.5734 - val_loss: 0.0803 - val_accuracy: 0.5658\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.08270 to 0.08029, saving model to /content/drive/My Drive/models/_mini_XCEPTION.14-0.57.hdf5\n",
            "Epoch 15/50\n",
            "898/897 [==============================] - 250s 279ms/step - loss: 0.0794 - accuracy: 0.5760 - val_loss: 0.0819 - val_accuracy: 0.5546\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.08029\n",
            "Epoch 16/50\n",
            "898/897 [==============================] - 250s 279ms/step - loss: 0.0783 - accuracy: 0.5851 - val_loss: 0.0845 - val_accuracy: 0.5414\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.08029\n",
            "Epoch 17/50\n",
            "898/897 [==============================] - 251s 280ms/step - loss: 0.0784 - accuracy: 0.5821 - val_loss: 0.0886 - val_accuracy: 0.5295\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.08029\n",
            "Epoch 18/50\n",
            "898/897 [==============================] - 250s 279ms/step - loss: 0.0778 - accuracy: 0.5866 - val_loss: 0.0847 - val_accuracy: 0.5471\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.08029\n",
            "Epoch 19/50\n",
            "898/897 [==============================] - 252s 281ms/step - loss: 0.0775 - accuracy: 0.5888 - val_loss: 0.0802 - val_accuracy: 0.5744\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.08029 to 0.08024, saving model to /content/drive/My Drive/models/_mini_XCEPTION.19-0.57.hdf5\n",
            "Epoch 20/50\n",
            "898/897 [==============================] - 250s 278ms/step - loss: 0.0767 - accuracy: 0.5950 - val_loss: 0.0802 - val_accuracy: 0.5741\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.08024 to 0.08019, saving model to /content/drive/My Drive/models/_mini_XCEPTION.20-0.57.hdf5\n",
            "Epoch 21/50\n",
            "898/897 [==============================] - 250s 278ms/step - loss: 0.0767 - accuracy: 0.5928 - val_loss: 0.0794 - val_accuracy: 0.5726\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.08019 to 0.07937, saving model to /content/drive/My Drive/models/_mini_XCEPTION.21-0.57.hdf5\n",
            "Epoch 22/50\n",
            "898/897 [==============================] - 250s 278ms/step - loss: 0.0763 - accuracy: 0.5979 - val_loss: 0.0759 - val_accuracy: 0.5943\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.07937 to 0.07593, saving model to /content/drive/My Drive/models/_mini_XCEPTION.22-0.59.hdf5\n",
            "Epoch 23/50\n",
            "898/897 [==============================] - 249s 277ms/step - loss: 0.0759 - accuracy: 0.6007 - val_loss: 0.0790 - val_accuracy: 0.5804\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.07593\n",
            "Epoch 24/50\n",
            "898/897 [==============================] - 248s 276ms/step - loss: 0.0755 - accuracy: 0.6015 - val_loss: 0.0795 - val_accuracy: 0.5875\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.07593\n",
            "Epoch 25/50\n",
            "898/897 [==============================] - 248s 277ms/step - loss: 0.0754 - accuracy: 0.6005 - val_loss: 0.0759 - val_accuracy: 0.5954\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.07593 to 0.07590, saving model to /content/drive/My Drive/models/_mini_XCEPTION.25-0.60.hdf5\n",
            "Epoch 26/50\n",
            "898/897 [==============================] - 249s 278ms/step - loss: 0.0752 - accuracy: 0.6019 - val_loss: 0.0751 - val_accuracy: 0.6003\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.07590 to 0.07515, saving model to /content/drive/My Drive/models/_mini_XCEPTION.26-0.60.hdf5\n",
            "Epoch 27/50\n",
            "898/897 [==============================] - 249s 277ms/step - loss: 0.0749 - accuracy: 0.6076 - val_loss: 0.0756 - val_accuracy: 0.6006\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.07515\n",
            "Epoch 28/50\n",
            "898/897 [==============================] - 249s 277ms/step - loss: 0.0745 - accuracy: 0.6081 - val_loss: 0.0759 - val_accuracy: 0.5986\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.07515\n",
            "Epoch 29/50\n",
            "898/897 [==============================] - 249s 277ms/step - loss: 0.0742 - accuracy: 0.6104 - val_loss: 0.0837 - val_accuracy: 0.5454\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.07515\n",
            "Epoch 30/50\n",
            "898/897 [==============================] - 251s 279ms/step - loss: 0.0736 - accuracy: 0.6123 - val_loss: 0.0752 - val_accuracy: 0.5988\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.07515\n",
            "Epoch 31/50\n",
            "898/897 [==============================] - 249s 278ms/step - loss: 0.0731 - accuracy: 0.6172 - val_loss: 0.0778 - val_accuracy: 0.5841\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.07515\n",
            "Epoch 32/50\n",
            "898/897 [==============================] - 250s 278ms/step - loss: 0.0733 - accuracy: 0.6144 - val_loss: 0.0766 - val_accuracy: 0.5901\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.07515\n",
            "Epoch 33/50\n",
            "898/897 [==============================] - 249s 278ms/step - loss: 0.0727 - accuracy: 0.6179 - val_loss: 0.0742 - val_accuracy: 0.6076\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.07515 to 0.07422, saving model to /content/drive/My Drive/models/_mini_XCEPTION.33-0.61.hdf5\n",
            "Epoch 34/50\n",
            "898/897 [==============================] - 249s 277ms/step - loss: 0.0729 - accuracy: 0.6193 - val_loss: 0.0783 - val_accuracy: 0.5931\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.07422\n",
            "Epoch 35/50\n",
            "898/897 [==============================] - 249s 277ms/step - loss: 0.0725 - accuracy: 0.6197 - val_loss: 0.0788 - val_accuracy: 0.5876\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.07422\n",
            "Epoch 36/50\n",
            "898/897 [==============================] - 249s 277ms/step - loss: 0.0726 - accuracy: 0.6189 - val_loss: 0.0755 - val_accuracy: 0.5977\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.07422\n",
            "Epoch 37/50\n",
            "898/897 [==============================] - 249s 278ms/step - loss: 0.0724 - accuracy: 0.6226 - val_loss: 0.0836 - val_accuracy: 0.5492\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.07422\n",
            "Epoch 38/50\n",
            "898/897 [==============================] - 249s 277ms/step - loss: 0.0717 - accuracy: 0.6259 - val_loss: 0.0751 - val_accuracy: 0.6030\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.07422\n",
            "Epoch 39/50\n",
            "898/897 [==============================] - 249s 277ms/step - loss: 0.0720 - accuracy: 0.6192 - val_loss: 0.0753 - val_accuracy: 0.6049\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.07422\n",
            "Epoch 40/50\n",
            "898/897 [==============================] - 249s 277ms/step - loss: 0.0717 - accuracy: 0.6214 - val_loss: 0.0751 - val_accuracy: 0.6064\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.07422\n",
            "Epoch 41/50\n",
            "898/897 [==============================] - 249s 277ms/step - loss: 0.0714 - accuracy: 0.6240 - val_loss: 0.0755 - val_accuracy: 0.6057\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.07422\n",
            "Epoch 42/50\n",
            "898/897 [==============================] - 249s 278ms/step - loss: 0.0712 - accuracy: 0.6291 - val_loss: 0.0740 - val_accuracy: 0.6062\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.07422 to 0.07403, saving model to /content/drive/My Drive/models/_mini_XCEPTION.42-0.61.hdf5\n",
            "Epoch 43/50\n",
            "898/897 [==============================] - 249s 278ms/step - loss: 0.0710 - accuracy: 0.6271 - val_loss: 0.0742 - val_accuracy: 0.6060\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.07403\n",
            "Epoch 44/50\n",
            "898/897 [==============================] - 250s 278ms/step - loss: 0.0712 - accuracy: 0.6276 - val_loss: 0.0724 - val_accuracy: 0.6206\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.07403 to 0.07242, saving model to /content/drive/My Drive/models/_mini_XCEPTION.44-0.62.hdf5\n",
            "Epoch 45/50\n",
            "898/897 [==============================] - 249s 278ms/step - loss: 0.0705 - accuracy: 0.6308 - val_loss: 0.0749 - val_accuracy: 0.6020\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.07242\n",
            "Epoch 46/50\n",
            "898/897 [==============================] - 250s 278ms/step - loss: 0.0704 - accuracy: 0.6327 - val_loss: 0.0790 - val_accuracy: 0.5836\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.07242\n",
            "Epoch 47/50\n",
            "898/897 [==============================] - 251s 279ms/step - loss: 0.0705 - accuracy: 0.6327 - val_loss: 0.0728 - val_accuracy: 0.6202\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.07242\n",
            "Epoch 48/50\n",
            "898/897 [==============================] - 251s 280ms/step - loss: 0.0702 - accuracy: 0.6347 - val_loss: 0.0749 - val_accuracy: 0.6041\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.07242\n",
            "Epoch 49/50\n",
            "898/897 [==============================] - 250s 278ms/step - loss: 0.0704 - accuracy: 0.6328 - val_loss: 0.0781 - val_accuracy: 0.5913\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.07242\n",
            "Epoch 50/50\n",
            "898/897 [==============================] - 249s 277ms/step - loss: 0.0698 - accuracy: 0.6358 - val_loss: 0.0744 - val_accuracy: 0.6077\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.07242\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f6791a22978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCU6solOrgRu",
        "colab_type": "code",
        "outputId": "6d380f17-27ce-4950-a06c-4b13b58cd89f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.image import img_to_array\n",
        "import imutils\n",
        "import cv2\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "# parameters for loading data and images\n",
        "detection_model_path = '/content/drive/My Drive/face/haarcascade_files/haarcascade_frontalface_default.xml'\n",
        "emotion_model_path = '/content/drive/My Drive/models/_mini_XCEPTION.44-0.62.hdf5'\n",
        "\n",
        "# hyper-parameters for bounding boxes shape\n",
        "# loading models\n",
        "face_detection = cv2.CascadeClassifier(detection_model_path)\n",
        "emotion_classifier = load_model(emotion_model_path, compile=False)\n",
        "EMOTIONS = [\"angry\" ,\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\n",
        " \"neutral\"]\n",
        "\n",
        "\n",
        "# starting video streaming\n",
        "cv2.namedWindow('your_face')\n",
        "camera = cv2.VideoCapture(0)\n",
        "while True:\n",
        "    frame = camera.read()[1]\n",
        "    #reading the frame\n",
        "    frame = imutils.resize(frame,width=400)\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_detection.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30,30),flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "    \n",
        "    canvas = np.zeros((250, 300, 3), dtype=\"uint8\")\n",
        "    frameClone = frame.copy()\n",
        "    if len(faces) > 0:\n",
        "        faces = sorted(faces, reverse=True,\n",
        "        key=lambda x: (x[2] - x[0]) * (x[3] - x[1]))[0]\n",
        "        (fX, fY, fW, fH) = faces\n",
        "                    # Extract the ROI of the face from the grayscale image, resize it to a fixed 48x48 pixels, and then prepare\n",
        "            # the ROI for classification via the CNN\n",
        "        roi = gray[fY:fY + fH, fX:fX + fW]\n",
        "        roi = cv2.resize(roi, (48, 48))\n",
        "        roi = roi.astype(\"float\") / 255.0\n",
        "        roi = img_to_array(roi)\n",
        "        roi = np.expand_dims(roi, axis=0)\n",
        "        \n",
        "        \n",
        "        preds = emotion_classifier.predict(roi)[0]\n",
        "        emotion_probability = np.max(preds)\n",
        "        label = EMOTIONS[preds.argmax()]\n",
        "\n",
        " \n",
        "    for (i, (emotion, prob)) in enumerate(zip(EMOTIONS, preds)):\n",
        "                # construct the label text\n",
        "                text = \"{}: {:.2f}%\".format(emotion, prob * 100)\n",
        "                w = int(prob * 300)\n",
        "                cv2.rectangle(canvas, (7, (i * 35) + 5),\n",
        "                (w, (i * 35) + 35), (0, 0, 255), -1)\n",
        "                cv2.putText(canvas, text, (10, (i * 35) + 23),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.45,\n",
        "                (255, 255, 255), 2)\n",
        "                cv2.putText(frameClone, label, (fX, fY - 10),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
        "                cv2.rectangle(frameClone, (fX, fY), (fX + fW, fY + fH),\n",
        "                              (0, 0, 255), 2)\n",
        "\n",
        "    cv2.imshow('your_face', frameClone)\n",
        "    cv2.imshow(\"Probabilities\", canvas)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "camera.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}